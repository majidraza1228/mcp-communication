# =============================================================================
# AI Provider Selection
# =============================================================================
# Choose "mock", "openai", or "bedrock"
AI_PROVIDER=mock

# =============================================================================
# Mock Provider (AI_PROVIDER=mock)
# =============================================================================
# No configuration needed! Use this for testing communication without API calls.
# Returns simulated responses like:
#   [MOCK RESPONSE #1] You said: 'Hello'. This is a test response.

# =============================================================================
# OpenAI Configuration (AI_PROVIDER=openai)
# =============================================================================
# OPENAI_API_KEY=sk-your-api-key-here
# OPENAI_DEFAULT_MODEL=gpt-4

# =============================================================================
# AWS Bedrock Configuration (AI_PROVIDER=bedrock)
# =============================================================================
# Authentication Option 1: Access Keys
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key

# Authentication Option 2: Named Profile (instead of access keys)
# AWS_PROFILE=your-profile-name

# Authentication Option 3: IAM Role (for EC2/Lambda/ECS - no env vars needed)
# Just ensure the IAM role has bedrock:InvokeModel permission

# Bedrock settings
# AWS_REGION=us-east-1
# BEDROCK_DEFAULT_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0

# Available Bedrock model shortcuts:
#   claude-3.5-sonnet-v2  -> anthropic.claude-3-5-sonnet-20241022-v2:0
#   claude-3.5-sonnet     -> anthropic.claude-3-5-sonnet-20240620-v1:0
#   claude-3.5-haiku      -> anthropic.claude-3-5-haiku-20241022-v1:0
#   claude-3-sonnet       -> anthropic.claude-3-sonnet-20240229-v1:0
#   claude-3-haiku        -> anthropic.claude-3-haiku-20240307-v1:0
#   claude-3-opus         -> anthropic.claude-3-opus-20240229-v1:0

# =============================================================================
# Shared AI Settings
# =============================================================================
AI_TEMPERATURE=0.7
AI_MAX_TOKENS=1000

# =============================================================================
# Server B HTTP Settings
# =============================================================================
HTTP_HOST=0.0.0.0
HTTP_PORT=8000

# =============================================================================
# Server A Settings
# =============================================================================
# For same machine:
SERVER_B_URL=http://localhost:8000

# For different machines (replace with Server B's IP/hostname):
# SERVER_B_URL=http://192.168.1.100:8000
# SERVER_B_URL=http://server-b.example.com:8000

TIMEOUT_SECONDS=120
RETRY_ATTEMPTS=3

# =============================================================================
# MCP Transport Settings
# =============================================================================
# Choose "stdio" (default) or "sse" (Streamable HTTP)
MCP_TRANSPORT=stdio

# SSE transport settings (only used when MCP_TRANSPORT=sse)
MCP_HOST=0.0.0.0
MCP_PORT_A=8001   # Server A MCP port
MCP_PORT_B=8002   # Server B MCP port
